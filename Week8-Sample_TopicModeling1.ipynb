{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Week8-Sample_TopicModeling1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuXlALnXQ3Fs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "33801b83-3b33-4091-b574-32ef3bb12b72"
      },
      "source": [
        "!rm -rf 6162-KDD\n",
        "!git clone https://github.com/nityanandkore/6162-KDD.git\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '6162-KDD'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 60 (delta 17), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (60/60), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc0fTQNcQtyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7edeadf5-79c9-4c32-bc4f-890f20a35a45"
      },
      "source": [
        "import pandas as pd\n",
        "!rm abcnews-date-text.csv\n",
        "!unzip '6162-KDD/DataSet/abcnews-date-text.zip'\n",
        "data = pd.read_csv('abcnews-date-text.csv')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  6162-KDD/DataSet/abcnews-date-text.zip\n",
            "  inflating: abcnews-date-text.csv   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JwzDEsaQtzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take a look at the content of the 'headline_text' column\n",
        "data_text = data[['headline_text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tNixjnhQtzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1edd2352-7c19-4ed0-945f-d017d757fae0"
      },
      "source": [
        "data_text"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1041788</th>\n",
              "      <td>who was alphabay founder alexandre cazes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1041789</th>\n",
              "      <td>wolfe brothers berry farming country music in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1041790</th>\n",
              "      <td>wollongong refugee ramps up liberian charity work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1041791</th>\n",
              "      <td>women choosing diy ivf sperm inseminsation to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1041792</th>\n",
              "      <td>young archie 2017 portraits shows australia ar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1041793 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             headline_text\n",
              "0        aba decides against community broadcasting lic...\n",
              "1           act fire witnesses must be aware of defamation\n",
              "2           a g calls for infrastructure protection summit\n",
              "3                 air nz staff in aust strike for pay rise\n",
              "4            air nz strike to affect australian travellers\n",
              "...                                                    ...\n",
              "1041788           who was alphabay founder alexandre cazes\n",
              "1041789  wolfe brothers berry farming country music in ...\n",
              "1041790  wollongong refugee ramps up liberian charity work\n",
              "1041791  women choosing diy ivf sperm inseminsation to ...\n",
              "1041792  young archie 2017 portraits shows australia ar...\n",
              "\n",
              "[1041793 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPWgAE1CQtzy",
        "colab_type": "code",
        "colab": {},
        "outputId": "1c00bfbb-4855-4d32-ef26-2326ba650a28"
      },
      "source": [
        "#add a column to data_text for the row index\n",
        "data_text['index'] = data_text.index\n",
        "documents = data_text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\P2190101\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVlmCLd6Qtz-",
        "colab_type": "code",
        "colab": {},
        "outputId": "4e40d12a-8dc5-4830-e295-aff529f4e048"
      },
      "source": [
        "len(documents)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1041793"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7F17Bj6Qt0K",
        "colab_type": "code",
        "colab": {},
        "outputId": "c84fe897-a0bd-4258-9b75-32ebcf2eb82f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\P2190101\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHbpm5tXQt0T",
        "colab_type": "code",
        "colab": {},
        "outputId": "fe2a2eb9-c770-4126-fe40-ec7041fb19ca"
      },
      "source": [
        "type(documents)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4OlsAH8Qt0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take a look at the content of a document with Index# 4310\n",
        "doc_sample = documents[documents['index'] == 4310].values[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WgMyReMQt0h",
        "colab_type": "code",
        "colab": {},
        "outputId": "57eb48c2-dc40-4ae5-999c-069abc097b87"
      },
      "source": [
        "doc_sample"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rain helps dampen bushfires'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dkSTyguQt0q",
        "colab_type": "code",
        "colab": {},
        "outputId": "d0286ba1-d192-4ff0-a0cb-b2a866d88cb1"
      },
      "source": [
        "documents[documents['index'] == 4310]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4310</th>\n",
              "      <td>rain helps dampen bushfires</td>\n",
              "      <td>4310</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    headline_text  index\n",
              "4310  rain helps dampen bushfires   4310"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hm_bj0uQt00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We will perform the following steps:\n",
        " #Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
        " #Words that have fewer than 3 characters are removed.\n",
        " #All stopwords are removed.\n",
        " #Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
        " #Words are stemmed — words are reduced to their root form.\n",
        "\n",
        "\n",
        "#import relvant packages for conduct topic modeling analysis\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(2018)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3kBhGa_Qt07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import*\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSGvaMXZQt1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#a function to perform lemmatize and stem preprocessing steps on the data set. You may \"Google\" each Python method to get the meaning of the parameters.\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQOtN-y1Qt1J",
        "colab_type": "code",
        "colab": {},
        "outputId": "83d9c1ef-d193-48be-b4b9-8a3d1cd1f88d"
      },
      "source": [
        "processed_docs[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               [decid, commun, broadcast, licenc]\n",
              "1                               [wit, awar, defam]\n",
              "2           [call, infrastructur, protect, summit]\n",
              "3                      [staff, aust, strike, rise]\n",
              "4             [strike, affect, australian, travel]\n",
              "5               [ambiti, olsson, win, tripl, jump]\n",
              "6           [antic, delight, record, break, barca]\n",
              "7    [aussi, qualifi, stosur, wast, memphi, match]\n",
              "8            [aust, address, secur, council, iraq]\n",
              "9                         [australia, lock, timet]\n",
              "Name: headline_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q15qf45PQt1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove na values from the column 'headline_text'\n",
        "documents = documents.dropna(subset=['headline_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFSb-ZzQQt1X",
        "colab_type": "code",
        "colab": {},
        "outputId": "f9ef002d-3d76-4b49-f248-b02ada247771"
      },
      "source": [
        "#select a document to preview after preprocessing\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rain', 'helps', 'dampen', 'bushfires']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['rain', 'help', 'dampen', 'bushfir']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeSCglEXQt1f",
        "colab_type": "code",
        "colab": {},
        "outputId": "e986ae82-aa6c-40a7-9832-91a41aff3572"
      },
      "source": [
        "#preprocess'headline_text', savie the results as 'processed_docs'\n",
        "processed_docs = documents['headline_text'].map(preprocess)\n",
        "processed_docs[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               [decid, commun, broadcast, licenc]\n",
              "1                               [wit, awar, defam]\n",
              "2           [call, infrastructur, protect, summit]\n",
              "3                      [staff, aust, strike, rise]\n",
              "4             [strike, affect, australian, travel]\n",
              "5               [ambiti, olsson, win, tripl, jump]\n",
              "6           [antic, delight, record, break, barca]\n",
              "7    [aussi, qualifi, stosur, wast, memphi, match]\n",
              "8            [aust, address, secur, council, iraq]\n",
              "9                         [australia, lock, timet]\n",
              "Name: headline_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTjAJt01Qt1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a dictionary from ‘processed_docs’ containing the number of times a word appears in the document set\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdcnjDeVQt1v",
        "colab_type": "code",
        "colab": {},
        "outputId": "b469d9df-7673-42a1-90c2-d89b3f8cee6b"
      },
      "source": [
        "dictionary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x1a4dd74fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjgaLO8tQt11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Filter out tokens that appear in\n",
        " #less than 15 documents (absolute number) or\n",
        " #more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
        " #after the above two steps, keep only the first 100000 most frequent tokens.\n",
        "\n",
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoFXodH2Qt17",
        "colab_type": "code",
        "colab": {},
        "outputId": "c9a43ef8-e6cd-4252-e943-4bb04f8da18f"
      },
      "source": [
        "#For each document we create a dictionary reporting how many\n",
        "#words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier.\n",
        "\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "bow_corpus[4310]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(76, 1), (112, 1), (483, 1), (4005, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnP5_B9HQt2A",
        "colab_type": "code",
        "colab": {},
        "outputId": "7fd539a4-6357-49de-806d-6f3167d718b2"
      },
      "source": [
        "bow_doc_4310 = bow_corpus[4310]\n",
        "for i in range(len(bow_doc_4310)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
        "                                               dictionary[bow_doc_4310[i][0]], \n",
        "bow_doc_4310[i][1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 76 (\"bushfir\") appears 1 time.\n",
            "Word 112 (\"help\") appears 1 time.\n",
            "Word 483 (\"rain\") appears 1 time.\n",
            "Word 4005 (\"dampen\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JISLMByQQt2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run LDA using bag of words\n",
        "\n",
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m9-rHsQQt2L",
        "colab_type": "code",
        "colab": {},
        "outputId": "b855e853-06e1-4b7c-ec3b-a4c7b5a9752c"
      },
      "source": [
        "#for each topic, we will explore the words occuring in that topic and its relative weight\n",
        "\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.049*\"australia\" + 0.026*\"world\" + 0.024*\"south\" + 0.022*\"second\" + 0.019*\"news\" + 0.017*\"test\" + 0.015*\"tasmanian\" + 0.014*\"women\" + 0.012*\"leagu\" + 0.011*\"lead\"\n",
            "Topic: 1 \n",
            "Words: 0.027*\"market\" + 0.022*\"trump\" + 0.021*\"busi\" + 0.016*\"share\" + 0.015*\"deal\" + 0.014*\"support\" + 0.013*\"return\" + 0.012*\"final\" + 0.012*\"citi\" + 0.011*\"bank\"\n",
            "Topic: 2 \n",
            "Words: 0.026*\"rural\" + 0.022*\"hour\" + 0.020*\"chang\" + 0.018*\"fund\" + 0.016*\"health\" + 0.015*\"live\" + 0.015*\"say\" + 0.013*\"minist\" + 0.013*\"school\" + 0.012*\"govern\"\n",
            "Topic: 3 \n",
            "Words: 0.018*\"attack\" + 0.017*\"kill\" + 0.017*\"fight\" + 0.013*\"near\" + 0.011*\"premier\" + 0.010*\"unit\" + 0.010*\"donald\" + 0.010*\"final\" + 0.009*\"risk\" + 0.009*\"say\"\n",
            "Topic: 4 \n",
            "Words: 0.020*\"elect\" + 0.018*\"govern\" + 0.015*\"tasmania\" + 0.013*\"say\" + 0.013*\"worker\" + 0.012*\"labor\" + 0.012*\"council\" + 0.011*\"meet\" + 0.010*\"protest\" + 0.009*\"strike\"\n",
            "Topic: 5 \n",
            "Words: 0.016*\"farm\" + 0.015*\"island\" + 0.013*\"centr\" + 0.013*\"sport\" + 0.012*\"park\" + 0.011*\"win\" + 0.011*\"darwin\" + 0.010*\"head\" + 0.010*\"million\" + 0.010*\"get\"\n",
            "Topic: 6 \n",
            "Words: 0.034*\"australian\" + 0.027*\"interview\" + 0.022*\"crash\" + 0.021*\"coast\" + 0.018*\"die\" + 0.017*\"miss\" + 0.015*\"polic\" + 0.014*\"gold\" + 0.014*\"north\" + 0.014*\"fall\"\n",
            "Topic: 7 \n",
            "Words: 0.039*\"year\" + 0.030*\"queensland\" + 0.024*\"face\" + 0.016*\"trial\" + 0.016*\"time\" + 0.015*\"weather\" + 0.015*\"australian\" + 0.014*\"west\" + 0.013*\"peopl\" + 0.013*\"victoria\"\n",
            "Topic: 8 \n",
            "Words: 0.018*\"farmer\" + 0.016*\"water\" + 0.013*\"concern\" + 0.013*\"industri\" + 0.013*\"break\" + 0.010*\"hill\" + 0.010*\"resid\" + 0.009*\"fear\" + 0.009*\"royal\" + 0.009*\"warn\"\n",
            "Topic: 9 \n",
            "Words: 0.036*\"polic\" + 0.028*\"charg\" + 0.025*\"court\" + 0.021*\"death\" + 0.019*\"murder\" + 0.017*\"home\" + 0.016*\"countri\" + 0.014*\"famili\" + 0.013*\"accus\" + 0.013*\"drug\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmpEDp86Qt2S",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f74f3ca-dbd7-45c6-bc74-eb257a75ecac"
      },
      "source": [
        "lda_model[bow_corpus[4310]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.020011147),\n",
              " (1, 0.24855973),\n",
              " (2, 0.02001444),\n",
              " (3, 0.020011147),\n",
              " (4, 0.020011682),\n",
              " (5, 0.020012455),\n",
              " (6, 0.020012716),\n",
              " (7, 0.020011147),\n",
              " (8, 0.34823185),\n",
              " (9, 0.2631237)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPEOuTKWQt2a",
        "colab_type": "code",
        "colab": {},
        "outputId": "7fd29c5a-2d4e-4a24-f173-8104afa80062"
      },
      "source": [
        "processed_docs[4310]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rain', 'help', 'dampen', 'bushfir']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhiuBjDNQt2e",
        "colab_type": "code",
        "colab": {},
        "outputId": "f0946ed7-5f88-4b2b-bf88-0891a9764c06"
      },
      "source": [
        "#check the topic distribution for the Document# 4310.\n",
        "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
        "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Score: 0.34802770614624023\t \n",
            "Topic: 0.018*\"farmer\" + 0.016*\"water\" + 0.013*\"concern\" + 0.013*\"industri\" + 0.013*\"break\" + 0.010*\"hill\" + 0.010*\"resid\" + 0.009*\"fear\" + 0.009*\"royal\" + 0.009*\"warn\"\n",
            "\n",
            "Score: 0.2632623016834259\t \n",
            "Topic: 0.036*\"polic\" + 0.028*\"charg\" + 0.025*\"court\" + 0.021*\"death\" + 0.019*\"murder\" + 0.017*\"home\" + 0.016*\"countri\" + 0.014*\"famili\" + 0.013*\"accus\" + 0.013*\"drug\"\n",
            "\n",
            "Score: 0.24862539768218994\t \n",
            "Topic: 0.027*\"market\" + 0.022*\"trump\" + 0.021*\"busi\" + 0.016*\"share\" + 0.015*\"deal\" + 0.014*\"support\" + 0.013*\"return\" + 0.012*\"final\" + 0.012*\"citi\" + 0.011*\"bank\"\n",
            "\n",
            "Score: 0.02001442015171051\t \n",
            "Topic: 0.026*\"rural\" + 0.022*\"hour\" + 0.020*\"chang\" + 0.018*\"fund\" + 0.016*\"health\" + 0.015*\"live\" + 0.015*\"say\" + 0.013*\"minist\" + 0.013*\"school\" + 0.012*\"govern\"\n",
            "\n",
            "Score: 0.020012693479657173\t \n",
            "Topic: 0.034*\"australian\" + 0.027*\"interview\" + 0.022*\"crash\" + 0.021*\"coast\" + 0.018*\"die\" + 0.017*\"miss\" + 0.015*\"polic\" + 0.014*\"gold\" + 0.014*\"north\" + 0.014*\"fall\"\n",
            "\n",
            "Score: 0.02001243270933628\t \n",
            "Topic: 0.016*\"farm\" + 0.015*\"island\" + 0.013*\"centr\" + 0.013*\"sport\" + 0.012*\"park\" + 0.011*\"win\" + 0.011*\"darwin\" + 0.010*\"head\" + 0.010*\"million\" + 0.010*\"get\"\n",
            "\n",
            "Score: 0.02001165971159935\t \n",
            "Topic: 0.020*\"elect\" + 0.018*\"govern\" + 0.015*\"tasmania\" + 0.013*\"say\" + 0.013*\"worker\" + 0.012*\"labor\" + 0.012*\"council\" + 0.011*\"meet\" + 0.010*\"protest\" + 0.009*\"strike\"\n",
            "\n",
            "Score: 0.02001112513244152\t \n",
            "Topic: 0.049*\"australia\" + 0.026*\"world\" + 0.024*\"south\" + 0.022*\"second\" + 0.019*\"news\" + 0.017*\"test\" + 0.015*\"tasmanian\" + 0.014*\"women\" + 0.012*\"leagu\" + 0.011*\"lead\"\n",
            "\n",
            "Score: 0.02001112513244152\t \n",
            "Topic: 0.018*\"attack\" + 0.017*\"kill\" + 0.017*\"fight\" + 0.013*\"near\" + 0.011*\"premier\" + 0.010*\"unit\" + 0.010*\"donald\" + 0.010*\"final\" + 0.009*\"risk\" + 0.009*\"say\"\n",
            "\n",
            "Score: 0.02001112513244152\t \n",
            "Topic: 0.039*\"year\" + 0.030*\"queensland\" + 0.024*\"face\" + 0.016*\"trial\" + 0.016*\"time\" + 0.015*\"weather\" + 0.015*\"australian\" + 0.014*\"west\" + 0.013*\"peopl\" + 0.013*\"victoria\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5sYd1qoQt2k",
        "colab_type": "code",
        "colab": {},
        "outputId": "bd6370bc-28d6-4c73-94cb-6ed34f501132"
      },
      "source": [
        "#check the topic distribution for a new document (not in the corpus)\n",
        "\n",
        "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.3503151535987854\t Topic: 0.027*\"market\" + 0.022*\"trump\" + 0.021*\"busi\" + 0.016*\"share\" + 0.015*\"deal\"\n",
            "Score: 0.18349500000476837\t Topic: 0.049*\"australia\" + 0.026*\"world\" + 0.024*\"south\" + 0.022*\"second\" + 0.019*\"news\"\n",
            "Score: 0.1833542287349701\t Topic: 0.034*\"australian\" + 0.027*\"interview\" + 0.022*\"crash\" + 0.021*\"coast\" + 0.018*\"die\"\n",
            "Score: 0.18272694945335388\t Topic: 0.036*\"polic\" + 0.028*\"charg\" + 0.025*\"court\" + 0.021*\"death\" + 0.019*\"murder\"\n",
            "Score: 0.016684820875525475\t Topic: 0.026*\"rural\" + 0.022*\"hour\" + 0.020*\"chang\" + 0.018*\"fund\" + 0.016*\"health\"\n",
            "Score: 0.016684768721461296\t Topic: 0.018*\"attack\" + 0.017*\"kill\" + 0.017*\"fight\" + 0.013*\"near\" + 0.011*\"premier\"\n",
            "Score: 0.016684768721461296\t Topic: 0.020*\"elect\" + 0.018*\"govern\" + 0.015*\"tasmania\" + 0.013*\"say\" + 0.013*\"worker\"\n",
            "Score: 0.016684768721461296\t Topic: 0.016*\"farm\" + 0.015*\"island\" + 0.013*\"centr\" + 0.013*\"sport\" + 0.012*\"park\"\n",
            "Score: 0.016684768721461296\t Topic: 0.039*\"year\" + 0.030*\"queensland\" + 0.024*\"face\" + 0.016*\"trial\" + 0.016*\"time\"\n",
            "Score: 0.016684768721461296\t Topic: 0.018*\"farmer\" + 0.016*\"water\" + 0.013*\"concern\" + 0.013*\"industri\" + 0.013*\"break\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B4hxDGGQt2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}